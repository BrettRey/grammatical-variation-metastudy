---
title: "Custom Stan Joint Selection Model"
author: "Brett Reynolds"
date: "2026-01-10"
format:
  html:
    toc: true
    code-fold: true
execute:
  warning: false
  message: false
---

## Setup

```{r}
#| label: setup
library(dplyr)
library(readr)
library(tidyr)
library(here)
library(rstan)
library(posterior)
library(ggplot2)

rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

## Prepare Data

```{r}
#| label: prepare-data
raw <- read_csv(here("analysis/gramm_var_prepped.csv"), show_col_types = FALSE) |>
  mutate(
    year_z = as.numeric(scale(year)),
    variation_type_recode = factor(variation_type_recode),
    journal = factor(journal),
    paper_id = factor(paper_id),
    author_id = factor(author_id),
    language_id = factor(language_id),
    tested = as.integer(tested),
    found = as.integer(found)
  )

X <- model.matrix(~ variation_type_recode + journal + year_z, data = raw)
X <- X[, -1, drop = FALSE]  # drop intercept; handled separately in Stan

stan_data <- list(
  N = nrow(raw),
  tested = raw$tested,
  found = ifelse(raw$tested == 1L, raw$found, 0L),
  K = ncol(X),
  X = X,
  J_paper = nlevels(raw$paper_id),
  J_author = nlevels(raw$author_id),
  J_language = nlevels(raw$language_id),
  paper_id = as.integer(raw$paper_id),
  author_id = as.integer(raw$author_id),
  language_id = as.integer(raw$language_id)
)
```

## Fit Model

```{r}
#| label: fit-model
fit_path <- here("analysis/fit_custom_stan.rds")
stan_path <- here("stan/selection_model.stan")

if (file.exists(fit_path)) {
  fit <- readRDS(fit_path)
} else {
  sm <- stan_model(stan_path)
  fit <- sampling(
    sm,
    data = stan_data,
    chains = 4,
    iter = 4000,
    warmup = 2000,
    seed = 123,
    control = list(adapt_delta = 0.99, max_treedepth = 12)
  )
  saveRDS(fit, fit_path)
}
```

## Diagnostics

```{r}
#| label: diagnostics
summ <- rstan::summary(fit)$summary
rhat <- summ[, "Rhat"]
n_eff <- summ[, "n_eff"]

diagnostics <- tibble(
  max_rhat = max(rhat, na.rm = TRUE),
  min_n_eff = min(n_eff, na.rm = TRUE),
  rhat_gt_1_01 = sum(rhat > 1.01, na.rm = TRUE),
  rhat_gt_1_05 = sum(rhat > 1.05, na.rm = TRUE)
)

sampler <- rstan::get_sampler_params(fit, inc_warmup = FALSE)
divergences <- sum(vapply(sampler, function(x) sum(x[, "divergent__"]), numeric(1)))
max_treedepth_observed <- max(vapply(sampler, function(x) max(x[, "treedepth__"]), numeric(1)))
max_treedepth_control <- 12
treedepth_hits <- sum(vapply(sampler, function(x) sum(x[, "treedepth__"] >= max_treedepth_control), numeric(1)))

diag_summary <- diagnostics |>
  mutate(
    divergences = divergences,
    max_treedepth_observed = max_treedepth_observed,
    max_treedepth_control = max_treedepth_control,
    treedepth_hits = treedepth_hits
  )

diag_summary
```

## Posterior Predictive Checks

```{r}
#| label: posterior-predictive
set.seed(123)
draws <- rstan::extract(
  fit,
  pars = c("alpha_s", "alpha_o", "beta_s", "beta_o",
           "u_paper", "u_author", "u_language")
)

n_draws <- length(draws$alpha_s)
draw_idx <- sample(seq_len(n_draws), size = min(200, n_draws))

inv_logit <- function(x) 1 / (1 + exp(-x))

simulate_rates <- function(i) {
  eta_s <- draws$alpha_s[i] +
    X %*% draws$beta_s[i, ] +
    draws$u_paper[i, 1, stan_data$paper_id] +
    draws$u_author[i, 1, stan_data$author_id] +
    draws$u_language[i, 1, stan_data$language_id]

  eta_o <- draws$alpha_o[i] +
    X %*% draws$beta_o[i, ] +
    draws$u_paper[i, 2, stan_data$paper_id] +
    draws$u_author[i, 2, stan_data$author_id] +
    draws$u_language[i, 2, stan_data$language_id]

  p_s <- inv_logit(eta_s)
  p_o <- inv_logit(eta_o)

  tested_rep <- rbinom(stan_data$N, 1, p_s)
  found_rep <- rbinom(stan_data$N, 1, p_o)

  tested_rate <- mean(tested_rep)
  found_rate <- ifelse(sum(tested_rep) > 0,
                       mean(found_rep[tested_rep == 1L]),
                       NA_real_)
  c(tested_rate = tested_rate, found_rate = found_rate)
}

rates <- t(vapply(draw_idx, simulate_rates, numeric(2)))
rates_df <- as_tibble(rates)

obs_tested <- mean(stan_data$tested)
obs_found <- mean(stan_data$found[stan_data$tested == 1L])

rates_long <- rates_df |>
  pivot_longer(cols = everything(), names_to = "metric", values_to = "rate")

obs_df <- tibble(
  metric = c("tested_rate", "found_rate"),
  observed = c(obs_tested, obs_found)
)

ggplot(rates_long, aes(x = rate)) +
  geom_density(fill = "#9ecae1", alpha = 0.6) +
  geom_vline(data = obs_df, aes(xintercept = observed), color = "#08306b", linewidth = 1) +
  facet_wrap(~ metric, scales = "free") +
  labs(
    title = "Posterior Predictive Checks (Rates)",
    subtitle = "Vertical line = observed rate",
    x = "Rate",
    y = "Density"
  )
```

## Stratified PPCs (Journal, Variation Type)

```{r}
#| label: stratified-ppc
group_defs <- list(
  journal = levels(raw$journal),
  variation_type_recode = levels(raw$variation_type_recode)
)

build_groups <- function(df, var) {
  df |> mutate(group = .data[[var]], group_var = var)
}

grouped_raw <- bind_rows(
  build_groups(raw, "journal"),
  build_groups(raw, "variation_type_recode")
)

group_levels <- grouped_raw |>
  distinct(group_var, group)

obs_group_rates <- grouped_raw |>
  group_by(group_var, group) |>
  summarize(
    tested_rate = mean(tested),
    found_rate = mean(found[tested == 1L]),
    .groups = "drop"
  )

simulate_group_rates <- function(i) {
  eta_s <- draws$alpha_s[i] +
    X %*% draws$beta_s[i, ] +
    draws$u_paper[i, 1, stan_data$paper_id] +
    draws$u_author[i, 1, stan_data$author_id] +
    draws$u_language[i, 1, stan_data$language_id]

  eta_o <- draws$alpha_o[i] +
    X %*% draws$beta_o[i, ] +
    draws$u_paper[i, 2, stan_data$paper_id] +
    draws$u_author[i, 2, stan_data$author_id] +
    draws$u_language[i, 2, stan_data$language_id]

  p_s <- inv_logit(eta_s)
  p_o <- inv_logit(eta_o)

  tested_rep <- rbinom(stan_data$N, 1, p_s)
  found_rep <- rbinom(stan_data$N, 1, p_o)

  sim_df <- raw |>
    mutate(
      tested_rep = tested_rep,
      found_rep = found_rep
    )

  sim_grouped <- bind_rows(
    build_groups(sim_df, "journal"),
    build_groups(sim_df, "variation_type_recode")
  )

  sim_grouped |>
    group_by(group_var, group) |>
    summarize(
      tested_rate = mean(tested_rep),
      found_rate = mean(found_rep[tested_rep == 1L]),
      .groups = "drop"
    )
}

sim_group_rates <- lapply(draw_idx, simulate_group_rates)
sim_group_rates_df <- bind_rows(sim_group_rates, .id = "draw") |>
  pivot_longer(cols = c(tested_rate, found_rate),
               names_to = "metric",
               values_to = "rate")

obs_group_long <- obs_group_rates |>
  pivot_longer(cols = c(tested_rate, found_rate),
               names_to = "metric",
               values_to = "observed")

ppc_plot <- sim_group_rates_df |>
  left_join(obs_group_long, by = c("group_var", "group", "metric")) |>
  ggplot(aes(x = rate)) +
  geom_density(fill = "#c7e9c0", alpha = 0.6) +
  geom_vline(aes(xintercept = observed), color = "#006d2c", linewidth = 0.8) +
  facet_grid(metric ~ group_var, scales = "free") +
  labs(
    title = "Stratified Posterior Predictive Checks",
    subtitle = "Vertical line = observed rate (by journal and variation type)",
    x = "Rate",
    y = "Density"
  )

ppc_plot
```

## Probability-Scale Predictions (Population Level)

```{r}
#| label: probability-plots
make_pred_grid <- function(df) {
  expand_grid(
    variation_type_recode = levels(df$variation_type_recode),
    journal = levels(df$journal),
    year_z = 0
  ) |>
    mutate(
      variation_type_recode = factor(variation_type_recode, levels = levels(df$variation_type_recode)),
      journal = factor(journal, levels = levels(df$journal))
    )
}

pred_grid <- make_pred_grid(raw)
X_pred <- model.matrix(~ variation_type_recode + journal + year_z, data = pred_grid)
X_pred <- X_pred[, -1, drop = FALSE]

pred_draws <- function(prefix_alpha, prefix_beta) {
  alpha <- draws[[prefix_alpha]][draw_idx]
  beta <- draws[[prefix_beta]][draw_idx, , drop = FALSE]
  eta <- sapply(seq_along(alpha), function(i) alpha[i] + X_pred %*% beta[i, ])
  inv_logit(eta)
}

pred_tested <- pred_draws("alpha_s", "beta_s")
pred_found <- pred_draws("alpha_o", "beta_o")

summarize_preds <- function(mat, label) {
  tibble(
    Estimate = apply(mat, 1, median),
    Q2.5 = apply(mat, 1, quantile, 0.025),
    Q97.5 = apply(mat, 1, quantile, 0.975),
    response = label
  )
}

preds <- bind_cols(pred_grid, summarize_preds(pred_tested, "tested")) |>
  bind_rows(bind_cols(pred_grid, summarize_preds(pred_found, "foundcond")))

ggplot(preds, aes(x = variation_type_recode, y = Estimate, color = journal)) +
  geom_point(position = position_dodge(width = 0.3)) +
  geom_errorbar(aes(ymin = Q2.5, ymax = Q97.5),
                width = 0.1,
                position = position_dodge(width = 0.3)) +
  facet_wrap(~ response, ncol = 1) +
  labs(
    title = "Predicted Probabilities by Variation Type & Journal (Population Level)",
    y = "Predicted probability",
    x = NULL,
    color = "Journal"
  )
```

## Fixed Effects (Odds Ratios)

```{r}
#| label: fixed-effects
as_draws <- posterior::as_draws_df(fit)

coef_names <- colnames(X)

summarize_beta <- function(prefix, response) {
  idx <- paste0(prefix, "[", seq_along(coef_names), "]")
  tibble(term = coef_names) |>
    mutate(
      median = sapply(idx, function(cn) median(exp(as_draws[[cn]]))),
      q2.5 = sapply(idx, function(cn) quantile(exp(as_draws[[cn]]), 0.025)),
      q97.5 = sapply(idx, function(cn) quantile(exp(as_draws[[cn]]), 0.975)),
      response = response
    )
}

intercepts <- tibble(
  term = "Intercept",
  response = c("tested", "foundcond"),
  median = c(median(exp(as_draws$alpha_s)), median(exp(as_draws$alpha_o))),
  q2.5 = c(quantile(exp(as_draws$alpha_s), 0.025), quantile(exp(as_draws$alpha_o), 0.025)),
  q97.5 = c(quantile(exp(as_draws$alpha_s), 0.975), quantile(exp(as_draws$alpha_o), 0.975))
)

or_table <- bind_rows(
  intercepts,
  summarize_beta("beta_s", "tested"),
  summarize_beta("beta_o", "foundcond")
) |>
  arrange(response, term)

or_table
```

```{r}
#| label: write-or-table
write_lines("# Custom Stan Joint Model OR Table\n", here("analysis/custom_stan_or_table.md"))

table_out <- or_table |>
  mutate(estimate = sprintf("%.2f [%.2f, %.2f]", median, q2.5, q97.5)) |>
  select(response, term, estimate) |>
  knitr::kable(format = "pipe")

write_lines(table_out, here("analysis/custom_stan_or_table.md"), append = TRUE)
```

## Random-Effect Correlations

```{r}
#| label: random-corr
corr <- rstan::extract(fit, pars = c("Corr_paper", "Corr_author", "Corr_language"))

summarize_corr <- function(arr, label) {
  vals <- arr[, 1, 2]
  tibble(
    group = label,
    median = median(vals),
    q2.5 = quantile(vals, 0.025),
    q97.5 = quantile(vals, 0.975)
  )
}

bind_rows(
  summarize_corr(corr$Corr_paper, "paper"),
  summarize_corr(corr$Corr_author, "author"),
  summarize_corr(corr$Corr_language, "language")
)
```
