% !TEX TS-program = xelatex
\documentclass[12pt]{article}

\input{.house-style/preamble.tex}
\input{local-preamble.tex}

\title{Grammatical Variation Meta-Study:\\ A Bayesian Reanalysis}
\author{Brett Reynolds \orcidlink{0000-0003-0073-7195}\\
  Humber Polytechnic \& University of Toronto\\
  \href{mailto:brett.reynolds@humber.ca}{brett.reynolds@humber.ca}}
\date{}

\begin{document}
\maketitle

\begin{abstract}
% TODO: Abstract
\end{abstract}

\section{Methods}

\subsection{Data and coding}
This reanalysis uses the open database compiled by \textcite{mackenzie2025spelling}, covering \emph{Language Variation and Change} (LVC) and the \emph{Journal of Sociolinguistics} (JSlx) from each journal's first year of publication through \liningnums{2023}. The unit of analysis is a variable--variety pairing. If a paper studies multiple variables or a variable across multiple varieties, each counts separately. The dataset contains \liningnums{427} variable--variety observations. Materials and code are available at \href{https://github.com/BrettRey/grammatical-variation-metastudy}{github.com/BrettRey/grammatical-variation-metastudy}.

Coding follows \textcite{mackenzie2025spelling}, which adapts the form--order--omission scheme of \textcite{mansfield2023dialect} and treats omission as a subtype of realization. Variables are included if they express grammatical meanings or functions in more than one way. Phonetic or phonological variables, lexical or discourse-pragmatic choice, discourse or conversation structure, and code-switching are excluded. The ambiguous variables (\mention{ING}) and (\mention{TD}) are also excluded. Variables are classified as \term{realization}, \term{order}, or \term{both}, with omission treated as a subtype of realization. The label \enquote{both} is used when a variable involves realization and order (for example, the dative alternation).

Social significance is coded as \enquote{not investigated}, \enquote{investigated but not found}, or \enquote{found}. When investigated, evidence is recorded as production, perception, or metalinguistic behaviors. In modeling, \enquote{tested} corresponds to \enquote{investigated}, and \enquote{found} is defined conditional on testing. Note that \enquote{found} means \enquote{reported as found}; the category \enquote{investigated but not found} is heterogeneous, encompassing genuinely absent effects, underpowered tests, and mismatched social-meaning targets. Because \enquote{both} is a coding convention rather than a theoretical category, a sensitivity check counts such variables in both realization and order categories; this doesn't change the qualitative selection pattern.

\subsection{Modeling strategy}
The goal is to separate two linked questions that variationists often discuss informally: which variables get tested for social meaning, and, once tested, which variables show social meaning. A joint selection--outcome model makes this explicit and avoids discarding untested rows. The selection stage models whether a variable is tested at all, and the outcome stage models whether social significance is found given testing. The outcome stage is directly analogous to mixed-effects logistic regression used in variable-rule analyses, but it is paired with a model for selection into testing. The model is fit in Stan, a probabilistic programming language for Bayesian inference.

Predictors in both stages are journal, variation type, and year (z-scored). Because year is z-scored, year odds ratios are interpretable as the change associated with a one-standard-deviation increase in publication year (roughly a decade in this corpus). Random intercepts for paper, first author, and language account for clustering, and correlations across stages allow the same paper or author to influence both testing and findings. This structure estimates selection into testing rather than treating it as unobserved noise.

Priors are regularizing on the logit scale: Normal$(0, 1.0)$ for intercepts, Normal$(0, 0.5)$ for slopes, Exponential$(3)$ for random-effect standard deviations, and LKJ$(2)$ for correlation matrices. A sensitivity run centers intercept priors on observed marginal rates while keeping slope and random-effect priors unchanged. Prior predictive checks are run under both prior sets to confirm that implied testing and finding rates are plausible. Sampling uses four chains, \liningnums{4000} iterations (\liningnums{2000} warmup), $\text{adapt\_delta}=0.99$, and \texttt{max\_treedepth} \liningnums{12}. A brms (Bayesian regression models using Stan) two-stage baseline provides comparison.

\section{Results}

\subsection{Model fit and predictive checks}
Posterior predictive checks (PPCs) ask whether replicated data from the fitted model resemble the observed data. Here, the replicated tested and found rates cluster around the observed rates overall and within journal and variation-type strata (Figures~\ref{fig:ppc-overall} and~\ref{fig:ppc-stratified}). The observed rates fall well inside the predictive distributions, suggesting that the model captures the main selection structure without apparent overfitting. Population-level predicted probabilities make the selection patterns easier to read (Figure~\ref{fig:probabilities}).

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{ppc-overall.png}
  \caption{Posterior predictive checks for overall tested and found rates. Vertical lines mark the observed rates.}
  \label{fig:ppc-overall}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{ppc-stratified.png}
  \caption{Stratified posterior predictive checks by journal and variation type. Vertical lines mark the observed rates.}
  \label{fig:ppc-stratified}
\end{figure}

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{probabilities.png}
  \caption{Population-level predicted probabilities by journal (color) and variation type. Points show posterior medians with 95\% credible intervals.}
  \label{fig:probabilities}
\end{figure}

\subsection{Selection (tested)}
Odds ratios (ORs) and credible intervals (CrIs) summarize the selection stage. Values above 1 mean higher odds of being tested, and values below 1 mean lower odds. Testing varies by journal, variation type, and year. LVC is less likely to test variables than JSlx (OR $\approx 0.37$, 95\% CrI 0.17--0.83). Realization variables are more likely to be tested than order variables (OR $\approx 2.33$, 95\% CrI 1.12--4.89). Testing increases over time (OR $\approx 1.65$, 95\% CrI 1.04--2.67). The order--both contrast remains uncertain.

\subsection{Outcome (found \texorpdfstring{$\mid$}{|} tested)}
Conditional on testing, success rates are high and comparable across types. The probability of finding social significance is high (approximately 88--94\% across subgroups) and shows wide overlap across journals and variation types. Outcome effects have intervals that span no effect, consistent with selection rather than capacity as the bottleneck. Wide credible intervals in sparse categories~-- order variables, perception and metalinguistic domains~-- reflect data limitations, not absence of effect. The model's partial pooling shrinks extreme estimates toward the population mean, so intervals spanning no effect should be read as \enquote{data cannot resolve this}, not \enquote{effect is absent.}

\subsection{Robustness}
The brms two-stage baseline yields the same qualitative pattern: selection effects are stable, outcome effects are weak. The centered-intercept sensitivity run reproduces the same conclusions.

An extended model adds a journal $\times$ variation-type interaction in the selection stage. If institutional framing requirements drive selection, JSlx might show a larger gap between realization and order than LVC. The interaction coefficients represent the multiplicative change in the LVC effect for each variation type relative to the reference (both). These coefficients have wide intervals spanning no effect (order:LVC OR $\approx 0.54$, 95\% CrI 0.23--1.29; realization:LVC OR $\approx 0.66$, 95\% CrI 0.30--1.47), so the data do not clearly support differential selection by journal.

A piecewise-linear year effect (two interior knots) tests whether selection trends are non-linear. The spline coefficients point in the same direction (ORs 1.19, 1.72, 1.32; all intervals spanning 1), consistent with the primary model's linear year assumption rather than distinct period effects.

\section{Discussion}

\subsection{Selection vs. outcome}
The main asymmetry is in selection. Journals, variable type, and time shape which variables are tested, but tested variables show high and overlapping probabilities of social significance. This supports a selection-driven account of the literature: the bottleneck is which variables are studied, not whether tested variables yield positive findings once investigated. This conclusion concerns publication and research-design practices rather than the underlying capacity of grammatical variables to carry social meaning.

\subsection{Implications for the Grammatical Invisibility Principle}
The Grammatical Invisibility Principle (GIP) holds that grammatical variables are less accessible to social evaluation than phonological variables. \textcite{mackenzie2025spelling} conclude that for realization variables, robust evidence of social significance exists; for order variables, absence of evidence does not equal evidence of absence. The present analysis sharpens this: \emph{conditional on testing}, both realization and order variables succeed at comparable rates (88--94\%). If order variables were genuinely invisible to social evaluation, one would expect lower success rates among those that are tested. Instead, the comparable rates suggest that the asymmetry in the published record reflects selection into testing, not a capacity difference. This finding refutes one version of the GIP~-- that order variables \emph{cannot} carry social meaning~-- while remaining agnostic about whether order variables are \emph{harder to perceive} or \emph{less frequently recruited} for social work.

\subsection{Relation to prior descriptive work}
The descriptive goal of \textcite{mackenzie2025spelling} is to catalog grammatical variables and assess the state of evidence for social significance in each domain. The present analysis retains their coding scheme and tallies without modification. The points of agreement are substantial: realization variables dominate the literature; order variables are understudied; perception and metalinguistic domains remain sparse.

The focused revision is methodological. MacKenzie and Robinson devote considerable discussion (their Section 5) to selection into testing, including the file drawer problem and the fact that LVC does not require a social-significance framing. They correctly note that this selection makes any claim about order variables provisional. What the present analysis adds is an explicit model for this selection mechanism. Rather than treating untested variables as missing data to be ignored, the joint model estimates the probability of testing and conditions the outcome analysis on testing. This quantifies what MacKenzie and Robinson discuss narratively: order variables are much less likely to be tested, and the scarcity of perception/metalinguistic studies in order variables limits conclusions about outcome differences.

The novelty is thus formalization rather than conceptual revision. The selection--outcome decomposition provides a principled statistical framework for claims that MacKenzie and Robinson already make informally. The difference in emphasis is slight: the high baseline success rate (~88--94\%) is the story, and the between-type comparison is null in part because of ceiling effects and limited order data.

\subsection{Limitations and future work}
Order variables are rare and heavily concentrated in LVC, so journal comparisons are constrained. Outcome effects are data-limited in sparse categories, especially perception and metalinguistic domains; with only 31 tested order variables, power to detect plausible outcome-stage differences is limited. Because the database indexes published studies, the model cannot address file-drawer effects where testing occurs but null results are not published. Future work should expand the corpus beyond two journals and target perception and metalinguistic studies for order variables. It also makes sense to explore alternative temporal structures and to refine the classification of multi-locus variables.

\appendix
\section{Model specification}

The joint selection--outcome model has two stages. For observation $i$:

\textbf{Selection stage:}
\begin{equation}
\text{tested}_i \sim \text{Bernoulli}(\text{logit}^{-1}(\eta^s_i))
\end{equation}
\begin{equation}
\eta^s_i = \alpha^s + \mathbf{x}_i \boldsymbol{\beta}^s + u^s_{\text{paper}[i]} + u^s_{\text{author}[i]} + u^s_{\text{language}[i]}
\end{equation}

\textbf{Outcome stage} (conditional on $\text{tested}_i = 1$):
\begin{equation}
\text{found}_i \mid \text{tested}_i = 1 \sim \text{Bernoulli}(\text{logit}^{-1}(\eta^o_i))
\end{equation}
\begin{equation}
\eta^o_i = \alpha^o + \mathbf{x}_i \boldsymbol{\beta}^o + u^o_{\text{paper}[i]} + u^o_{\text{author}[i]} + u^o_{\text{language}[i]}
\end{equation}

where $\mathbf{x}_i$ is the row of the fixed-effects design matrix containing journal, variation type, and year (z-scored).

\textbf{Random effects:} For each grouping factor $g \in \{\text{paper}, \text{author}, \text{language}\}$:
\begin{equation}
\begin{pmatrix} u^s_{g[i]} \\ u^o_{g[i]} \end{pmatrix} \sim \text{MVN}\left(\mathbf{0}, \boldsymbol{\Sigma}_g\right), \quad \boldsymbol{\Sigma}_g = \begin{pmatrix} \sigma^s_g & \rho_g \sigma^s_g \sigma^o_g \\ \rho_g \sigma^s_g \sigma^o_g & \sigma^o_g \end{pmatrix}
\end{equation}

\textbf{Priors:}
\begin{align}
\alpha^s, \alpha^o &\sim \text{Normal}(0, 1.0) \\
\beta^s_k, \beta^o_k &\sim \text{Normal}(0, 0.5) \\
\sigma^s_g, \sigma^o_g &\sim \text{Exponential}(3) \\
\mathbf{L}_g &\sim \text{LKJ-Cholesky}(2)
\end{align}

where $\mathbf{L}_g$ is the Cholesky factor of the correlation matrix for grouping factor $g$.

\printbibliography

\end{document}
